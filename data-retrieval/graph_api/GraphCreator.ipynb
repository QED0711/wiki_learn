{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../utils/\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pdb\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import signal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from wiki_intro_scrapper import WikiIntroScrapper\n",
    "\n",
    "%aimport wiki_intro_scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphCreator:\n",
    "\n",
    "    def __init__(self, entry):\n",
    "        self.graph = nx.DiGraph()\n",
    "\n",
    "        self.next_links = self.get_article_info(entry)['links']\n",
    "        self.seen = {entry}\n",
    "\n",
    "        # setup timeout function\n",
    "        def handle_alarm(signum, frame):\n",
    "            raise RuntimeError\n",
    "\n",
    "        signal.signal(signal.SIGALRM, handle_alarm)\n",
    "\n",
    "    def has_key(self, key, resp, pageid):\n",
    "        return bool(resp['query'][\"pages\"][pageid].get(key))\n",
    "\n",
    "    def add_edges(self, article_info):\n",
    "        self.graph.add_edges_from([(article_info['title'], link)\n",
    "                                   for link in article_info['links']])\n",
    "        self.graph.add_edges_from(\n",
    "            [(linkhere, article_info['title']) for linkhere in article_info['linkshere']])\n",
    "\n",
    "    def plot_graph(self):\n",
    "        nx.draw(self.graph)\n",
    "        plt.show()\n",
    "\n",
    "    def get_degrees(self):\n",
    "        return sorted([(key, val) for key, val in dict(self.graph.degree()).items()], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    def get_centrality(self, sort_results=False):\n",
    "        if sort_results:\n",
    "            return sorted([(key, val) for key, val in dict(nx.eigenvector_centrality(self.graph)).items()], key=lambda x: x[1], reverse=True)\n",
    "        else:\n",
    "            return nx.eigenvector_centrality(self.graph)\n",
    "\n",
    "    def expand_network(self):\n",
    "        num_links = len(self.next_links)\n",
    "        for i in range(num_links):\n",
    "            link = self.next_links.pop(0)\n",
    "            if not link in self.seen:\n",
    "                try:\n",
    "                    signal.alarm(3)\n",
    "                    print(i, link)\n",
    "                    self.seen.add(link)\n",
    "                    self.next_links += self.get_article_info(link)\n",
    "                    signal.alarm(0)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    def get_article_info(self, title, generate_graph=True):\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "\n",
    "            \"titles\": title,\n",
    "\n",
    "            \"prop\": \"extracts|redirects|links|linkshere|categories\",\n",
    "\n",
    "            # extracts\n",
    "            \"exintro\": True,\n",
    "            \"explaintext\": True,\n",
    "            \"exsectionformat\": \"plain\",\n",
    "\n",
    "            # redirects\n",
    "            \"rdnamespace\": 0,\n",
    "            \"rdlimit\": \"max\",\n",
    "\n",
    "            # links\n",
    "            \"pllimit\": \"max\",\n",
    "            \"plnamespace\": 0,\n",
    "\n",
    "            # linkshere\n",
    "            \"lhlimit\": \"max\",\n",
    "            \"lhnamespace\": 0,\n",
    "            \"lhshow\": \"!redirect\",\n",
    "\n",
    "            # categories\n",
    "            \"cllimit\": \"max\",\n",
    "\n",
    "            # automatic redirect\n",
    "            \"redirects\": 1\n",
    "        }\n",
    "\n",
    "        article_id = []\n",
    "        extract = []\n",
    "        redirects = []\n",
    "        links = []\n",
    "        linkshere = []\n",
    "        categories = []\n",
    "\n",
    "        def query_info(title, params):\n",
    "\n",
    "            resp = requests.get(\n",
    "                url=\"https://en.wikipedia.org/w/api.php\",\n",
    "                params=params).json()\n",
    "\n",
    "#             pdb.set_trace()\n",
    "\n",
    "            pageid = list(resp[\"query\"]['pages'].keys())[0]\n",
    "\n",
    "            article_id.append(pageid)\n",
    "\n",
    "            if self.has_key(\"extract\", resp, pageid):\n",
    "                extract.append(resp['query'][\"pages\"][pageid]['extract'])\n",
    "\n",
    "            if self.has_key(\"redirects\", resp, pageid):\n",
    "                for rd in resp['query'][\"pages\"][pageid][\"redirects\"]:\n",
    "                    redirects.append(rd[\"title\"])\n",
    "\n",
    "            if self.has_key(\"links\", resp, pageid):\n",
    "                for link in resp['query'][\"pages\"][pageid][\"links\"]:\n",
    "                    links.append(link[\"title\"])\n",
    "\n",
    "            if self.has_key(\"linkshere\", resp, pageid):\n",
    "                for lh in resp['query'][\"pages\"][pageid][\"linkshere\"]:\n",
    "                    linkshere.append(lh[\"title\"])\n",
    "\n",
    "            if self.has_key(\"categories\", resp, pageid):\n",
    "                for cat in resp['query'][\"pages\"][pageid][\"categories\"]:\n",
    "                    if not bool(re.findall(r\"(articles)|(uses)|(commons)\", cat[\"title\"], re.I)):\n",
    "                        categories.append(cat[\"title\"])\n",
    "\n",
    "            if resp.get('continue'):\n",
    "                params.update(resp.get(\"continue\"))\n",
    "                query_info(title, params)\n",
    "\n",
    "        query_info(title, params)\n",
    "\n",
    "        article_info = {\n",
    "            \"pageid\": int(article_id[0]),\n",
    "            \"title\": title,\n",
    "            \"extract\": extract,\n",
    "            \"redirects\": redirects,\n",
    "            \"links\": links,\n",
    "            \"linkshere\": linkshere,\n",
    "            \"categories\": categories,\n",
    "        }\n",
    "\n",
    "        if generate_graph:\n",
    "            self.add_edges(article_info)\n",
    "\n",
    "        return article_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gc = GraphCreator(\"Random forest\")\n",
    "wis = WikiIntroScrapper(\"https://en.wikipedia.org/wiki/Random_forest\")\n",
    "wis.parse_intro_links();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ensemble learning',\n",
       " 'Statistical classification',\n",
       " 'Regression analysis',\n",
       " 'Decision tree learning',\n",
       " 'Mode (statistics)',\n",
       " 'Overfitting',\n",
       " 'Test set',\n",
       " 'Tin Kam Ho',\n",
       " 'Random subspace method',\n",
       " 'Leo Breiman',\n",
       " 'Trademark',\n",
       " 'Minitab',\n",
       " 'Bootstrap aggregating',\n",
       " 'Donald Geman']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wis.intro_link_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest 0.6037188521312119\n",
      "Ensemble learning 0.06835910518451588\n",
      "Statistical classification 0.06835910518451588\n",
      "Regression analysis 0.06835910518451588\n",
      "Decision tree learning 0.06835910518451588\n",
      "Mode (statistics) 0.06835910518451588\n",
      "Overfitting 0.06835910518451588\n",
      "Test set 0.06835910518451588\n",
      "Tin Kam Ho 0.06835910518451588\n",
      "Random subspace method 0.06835910518451588\n",
      "Leo Breiman 0.06835910518451588\n",
      "Trademark 0.06835910518451588\n",
      "Minitab 0.06835910518451588\n",
      "Bootstrap aggregating 0.06835910518451588\n",
      "Donald Geman 0.06835910518451588\n"
     ]
    }
   ],
   "source": [
    "centrality = gc.get_centrality()\n",
    "print (wis.title, centrality[wis.title])\n",
    "for title in wis.intro_link_titles:\n",
    "    print(title, centrality[title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Annals of Mathematics and Artificial Intelligence\n",
      "1 Annals of Statistics\n",
      "2 Anomaly detection\n",
      "3 ArXiv\n",
      "4 Artificial neural network\n",
      "5 Artificial neural networks\n",
      "6 Association rule learning\n",
      "7 Autoencoder\n",
      "8 Automated machine learning\n",
      "9 BIRCH\n",
      "10 Bayesian network\n",
      "11 Bias–variance dilemma\n",
      "12 Bias–variance tradeoff\n",
      "13 Boosting (machine learning)\n",
      "14 Bootstrap aggregating\n",
      "15 CURE data clustering algorithm\n",
      "16 Canonical correlation analysis\n",
      "17 CiteSeerX\n",
      "18 Classification and regression tree\n",
      "19 Cluster analysis\n",
      "20 Computational learning theory\n",
      "21 Conditional random field\n",
      "22 Conference on Neural Information Processing Systems\n",
      "23 Convolutional neural network\n",
      "24 Correlation\n",
      "25 Cross-validation (statistics)\n",
      "26 DBSCAN\n",
      "27 Data mining\n",
      "28 Decision tree\n",
      "29 Decision tree learning\n",
      "30 DeepDream\n",
      "31 Deep learning\n",
      "32 Digital object identifier\n",
      "33 Dimensionality reduction\n",
      "34 Donald Geman\n",
      "35 Empirical risk minimization\n",
      "36 Ensemble learning\n",
      "37 Expectation–maximization algorithm\n",
      "38 Factor analysis\n",
      "39 Feature (machine learning)\n",
      "40 Feature engineering\n",
      "41 Feature learning\n",
      "42 Gated recurrent unit\n",
      "43 Generalization error\n",
      "44 Generative adversarial network\n",
      "45 Gini impurity\n",
      "46 Glossary of artificial intelligence\n",
      "47 Gradient boosting\n",
      "48 Grammar induction\n",
      "49 Graphical model\n",
      "50 Hidden Markov model\n",
      "51 Hierarchical clustering\n",
      "52 I.i.d.\n",
      "53 Independent component analysis\n",
      "54 Information gain\n",
      "55 International Conference on Machine Learning\n",
      "56 International Standard Book Number\n",
      "57 JSTOR\n",
      "58 Jerome H. Friedman\n",
      "59 Journal of Machine Learning Research\n",
      "60 K-means clustering\n",
      "61 K-nearest neighbor algorithm\n",
      "62 K-nearest neighbors algorithm\n",
      "63 K-nearest neighbors classification\n",
      "64 Kernel method\n",
      "65 Kernel methods\n",
      "66 Kernel random forest\n",
      "67 Learning to rank\n",
      "68 Lecture Notes in Computer Science\n",
      "69 Leo Breiman\n",
      "70 Linear discriminant analysis\n",
      "71 Linear regression\n",
      "72 Linear subspace\n",
      "73 Lipschitz\n",
      "74 List of datasets for machine-learning research\n",
      "75 Local outlier factor\n",
      "76 Logistic regression\n",
      "77 Long short-term memory\n",
      "78 Machine Learning (journal)\n",
      "79 Machine learning\n",
      "80 Mathematical Reviews\n",
      "81 Mean-shift\n",
      "82 Minitab\n",
      "83 Mode (statistics)\n",
      "84 Multilayer perceptron\n",
      "85 Multinomial logistic regression\n",
      "86 Naive Bayes classifier\n",
      "87 Neural Computation (journal)\n",
      "88 Non-negative matrix factorization\n",
      "89 Non-parametric statistics\n",
      "90 OPTICS algorithm\n",
      "91 Occam learning\n",
      "92 Online machine learning\n",
      "93 Orange (software)\n",
      "94 Out-of-bag error\n",
      "95 Outline of machine learning\n",
      "96 Overfitting\n",
      "97 Partial permutation\n",
      "98 Perceptron\n",
      "99 Principal component analysis\n",
      "100 Probably approximately correct learning\n",
      "101 PubMed Central\n",
      "102 PubMed Identifier\n",
      "103 Q-learning\n",
      "104 R (programming language)\n",
      "105 R programming language\n",
      "106 Random forests\n",
      "107 Random subspace method\n",
      "108 Random tree\n",
      "109 Randomized algorithm\n",
      "110 Recurrent neural network\n",
      "111 Regression analysis\n",
      "112 Reinforcement learning\n",
      "113 Relevance vector machine\n",
      "114 Restricted Boltzmann machine\n",
      "115 Robert Tibshirani\n",
      "116 Sampling (statistics)\n",
      "117 Scikit-learn\n",
      "118 Self-organizing map\n",
      "119 Semi-supervised learning\n",
      "120 State–action–reward–state–action\n",
      "121 Statistical classification\n",
      "122 Statistical learning theory\n",
      "123 Structured prediction\n",
      "124 Supervised learning\n",
      "125 Support-vector machine\n",
      "126 T-distributed stochastic neighbor embedding\n",
      "127 Temporal difference learning\n",
      "128 Test set\n",
      "129 Tin Kam Ho\n",
      "130 Trademark\n",
      "131 Trevor Hastie\n",
      "132 U-Net\n",
      "133 Unsupervised learning\n",
      "134 Vapnik–Chervonenkis theory\n",
      "135 Wikipedia\n"
     ]
    }
   ],
   "source": [
    "gc.expand_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regression analysis</td>\n",
       "      <td>0.158336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statistical classification</td>\n",
       "      <td>0.149279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree learning</td>\n",
       "      <td>0.083674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bootstrap aggregating</td>\n",
       "      <td>0.083298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ensemble learning</td>\n",
       "      <td>0.082659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0.081253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mode (statistics)</td>\n",
       "      <td>0.081252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Overfitting</td>\n",
       "      <td>0.027596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leo Breiman</td>\n",
       "      <td>0.010554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Test set</td>\n",
       "      <td>0.007041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Minitab</td>\n",
       "      <td>0.006013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random subspace method</td>\n",
       "      <td>0.005361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trademark</td>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Donald Geman</td>\n",
       "      <td>0.002748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tin Kam Ho</td>\n",
       "      <td>0.002572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  centrality\n",
       "0          Regression analysis    0.158336\n",
       "1   Statistical classification    0.149279\n",
       "2       Decision tree learning    0.083674\n",
       "3        Bootstrap aggregating    0.083298\n",
       "4            Ensemble learning    0.082659\n",
       "5                Random forest    0.081253\n",
       "6            Mode (statistics)    0.081252\n",
       "7                  Overfitting    0.027596\n",
       "8                  Leo Breiman    0.010554\n",
       "9                     Test set    0.007041\n",
       "10                     Minitab    0.006013\n",
       "11      Random subspace method    0.005361\n",
       "12                   Trademark    0.002945\n",
       "13                Donald Geman    0.002748\n",
       "14                  Tin Kam Ho    0.002572"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centrality = gc.get_centrality()\n",
    "\n",
    "rankings = []\n",
    "\n",
    "rankings.append((wis.title, centrality[wis.title]))\n",
    "for title in wis.intro_link_titles:\n",
    "    rankings.append((title, centrality[title]))\n",
    "    \n",
    "ranking_df = pd.DataFrame(rankings, columns=[\"title\", \"centrality\"])\n",
    "ranking_df.sort_values(\"centrality\", ascending=False).reset_index().drop('index', axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
