{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../utils\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import pdb\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import pymongo\n",
    "\n",
    "from keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_key(key, resp, pageid):\n",
    "    return bool(resp['query'][\"pages\"][pageid].get(key))\n",
    "\n",
    "def matches(lst1, lst2):\n",
    "    return [x for x in lst1 if x in lst2]\n",
    "    \n",
    "    \n",
    "def get_article_info(title):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "\n",
    "        \"titles\": title,\n",
    "\n",
    "        \"prop\": \"info|links|linkshere|categories\",\n",
    "        \n",
    "        # links\n",
    "        \"pllimit\": \"max\",\n",
    "        \"plnamespace\": 0,\n",
    "        \n",
    "        # linkshere\n",
    "        \"lhlimit\": \"max\",\n",
    "        \"lhnamespace\": 0,\n",
    "        \"lhshow\": \"!redirect\",\n",
    "        \n",
    "        # categories\n",
    "        \"cllimit\": \"max\",\n",
    "    }\n",
    "\n",
    "    links = []\n",
    "    linkshere = []\n",
    "    categories = []\n",
    "\n",
    "    def query_info(title, params):\n",
    "\n",
    "        resp = requests.get(\n",
    "            url=\"https://en.wikipedia.org/w/api.php\",\n",
    "            params=params).json()\n",
    "\n",
    "        pageid = list(resp[\"query\"]['pages'].keys())[0]\n",
    "\n",
    "        if has_key(\"links\", resp, pageid):\n",
    "            for link in resp['query'][\"pages\"][pageid][\"links\"]:\n",
    "                links.append(link[\"title\"])\n",
    "        \n",
    "        if has_key(\"linkshere\", resp, pageid):\n",
    "            for lh in resp['query'][\"pages\"][pageid][\"linkshere\"]:\n",
    "                linkshere.append(lh[\"title\"])\n",
    "        \n",
    "        if has_key(\"categories\", resp, pageid):\n",
    "            for cat in resp['query'][\"pages\"][pageid][\"categories\"]:\n",
    "                if not bool(re.findall(r\"(articles)|(uses)|(commons)\", cat[\"title\"], re.I)):\n",
    "                    categories.append(cat[\"title\"])\n",
    "        \n",
    "        if resp.get('continue'):\n",
    "            params.update(resp.get(\"continue\"))\n",
    "            query_info(title, params)\n",
    "\n",
    "    query_info(title, params)\n",
    "    \n",
    "    return links, linkshere, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "links1, linkshere1, categories1 = get_article_info(\"Random forest\")\n",
    "\n",
    "links2, linkshere2, categories2 = get_article_info(\"Decision tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Category:Decision trees']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches(categories1, categories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_articles = pd.read_csv(\"../../data/raw/05_expanded_labaled_removed_comparisons.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207488, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class WikiAPI:\n",
    "\n",
    "    def __init__(self, df, collection=\"article_links\"):\n",
    "\n",
    "        self.df = df\n",
    "        self.seen = {}\n",
    "        \n",
    "        # mlab setup\n",
    "        uri = f\"mongodb://{mlab_api['username']}:{mlab_api['password']}@ds261277.mlab.com:61277/wiki_scrapper\"\n",
    "        client = pymongo.MongoClient(uri)\n",
    "        db = client.get_default_database()\n",
    "        self.collection = db[collection]\n",
    "\n",
    "    def get_and_save_info(self, title):\n",
    "        links, linkshere, categories = get_article_info(title)\n",
    "        return {\"_id\": title, \"links\": links, \"linkshere\": linkshere, \"categories\": categories}\n",
    "\n",
    "    def get_api_info(self):\n",
    "\n",
    "        for i, row in self.df.iterrows():\n",
    "\n",
    "            if not self.seen.get(row[\"parent_title\"]):\n",
    "                parent_info = self.get_and_save_info(row[\"parent_title\"])\n",
    "#                 print(parent_info, \"\\n\\n\")\n",
    "                self.to_mlab(parent_info)\n",
    "                self.seen[row[\"parent_title\"]] = set([\"parent\"])\n",
    "            else:\n",
    "                self.seen[row[\"parent_title\"]].add(\"parent\")\n",
    "\n",
    "            if not self.seen.get(row[\"child_title\"]):\n",
    "                child_info = self.get_and_save_info(row[\"child_title\"])\n",
    "#                 print(child_info, \"\\n\\n\")\n",
    "                self.to_mlab(child_info)\n",
    "                self.seen[row[\"child_title\"]] = set([\"child\"])\n",
    "            else:\n",
    "                self.seen[row[\"child_title\"]].add(\"child\")\n",
    "    \n",
    "        return self.seen_to_csv()\n",
    "    \n",
    "    def to_mlab(self, article_info):\n",
    "        try:\n",
    "            self.collection.insert_one(article_info)\n",
    "        except:\n",
    "            return\n",
    "        \n",
    "    def seen_to_csv(self):\n",
    "        for title, relation in self.seen.items():\n",
    "            self.seen[title] = list(relation)\n",
    "            \n",
    "        seen_df = pd.DataFrame(self.seen).T.reset_index()\n",
    "        seen_df.columns = [\"name\", \"relation\"]\n",
    "        seen_df.to_csv(\"article_title_relationships.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = related_articles[0:2].copy()\n",
    "api = WikiAPI(test_set)\n",
    "\n",
    "api.get_api_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
